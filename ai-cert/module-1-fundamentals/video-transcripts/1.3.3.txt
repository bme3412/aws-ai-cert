Let's continue with the third task statement from Domain 1, which is to describe the ML development lifecycle.

The next phase of the pipeline is where we get to train, tune, and evaluate the model. In this phase, we are teaching the model, through an iterative process of training, tuning, and evaluating. During training, the machine learning algorithm updates a set of numbers, known as parameters or weights.

The goal is to update the parameters in the model in such a way that the inference matches the expected output. This can't be done in one iteration, because the algorithm has not learned yet. It has no knowledge of how changing weights will shift the output closer toward the expected value. Therefore, it watches the weights and outputs from previous iterations, and shifts the weights to a direction that lowers the error in generated output.

This iterative process stops either when a defined number of iterations have been run, or when the change in error is below a target value. There are usually multiple algorithms to consider for a model. The best practice is to run many training jobs in parallel, by using different algorithms and settings. This is known as running experiments, which helps you land on the best-performing solution. Each algorithm has a set of external parameters that affect its performance, known as hyperparameters. These are set by the data scientists before training the model. These include adjusting things like how many neural layers and nodes there will be in a deep learning model. The optimal values for the hyperparameters can only be determined by running multiple experiments with different settings.

To train your model using SageMaker, you create a training job which runs your training code on a fleet of ML compute instances managed by SageMaker. To create a training job, you specify the URL of the S3 bucket containing your training data. You also specify the compute resources you want to use for training, and the output bucket for the model artifacts. You specify the algorithm by giving SageMaker the path to a Docker container image that contains the training algorithm. In the Amazon Elastic Container Registry, Amazon ECR, you can specify the location of SageMaker provided algorithms and deep learning containers, or the location of your custom container, containing a custom algorithm.

You also need to set the hyperparameters required by the algorithm. After you create the training job, SageMaker launches the ML compute instances, and uses the training code and the training dataset to train the model. It saves the resulting model artifacts and other outputs in the S3 bucket you specified for that purpose.

We've seen that machine learning is an iterative process. You need to experiment with multiple combinations of data, algorithms, and parameters, all while observing the impact of incremental changes on model accuracy. This iterative experimentation can result in thousands of model training runs and model versions.

Amazon SageMaker experiments is a capability of Amazon SageMaker that lets you create, manage, analyze, and compare your machine learning experiments. An experiment is a group of training runs, each with different inputs, parameters, and configurations. It features a visual interface to browse your active and past experiments, compare runs on key performance metrics, and identify the best-performing models.

Amazon SageMaker automatic model tuning, AMT, also known as hyperparameter tuning, finds the best version of a model, by running many training jobs on your dataset. To do this, AMT uses the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that create a model that performs it best, as measured by a metric that you choose. For example, suppose that you are tuning a binary classification model.

You can have automatic model tuning find the combination of hyperparameters that maximizes a metric known as the area under the curve. To use automatic model tuning, you can figure a tuning job that runs several training jobs inside a loop. You specify completion criteria as the number of jobs that are no longer improving the metric. The job will run until the completion criteria are satisfied.